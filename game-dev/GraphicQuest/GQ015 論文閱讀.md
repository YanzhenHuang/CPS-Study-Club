# 論文閱讀
本次閱讀的三篇論文:
1. Bilateral Mesh Denoising
2. Mesh Saliency
3. Fast and Effective Feature-Preserving Mesh Denoising

# 參考代碼：
https://github.com/bldeng/GuidedDenoising

# Bilateral Mesh Denoising
- Bilateral Mesh Denoising
  - Shachar Fleishman Iddo Drori Daniel Cohen-Or

# 1.1 Bilateral Mesh Denoising 
Bilateral Mesh Denoising : 
> 有效、簡單、快速的各向異性網格去噪算法。這是通過使用局部鄰域過濾法線方向上的網格頂點來實現的。受圖像去噪雙邊濾波令人印象深刻的結果的啟發，我們採用它對 3D 網格進行去噪；解決從二維向三維流形過渡所需的具體問題。我們表明，所提出的方法成功地從網格中去除了噪聲，同時保留了特徵。此外，所提出的算法在概念和實現上都非常簡單。

# 1.2 Why we need Denoising?
> 圖像處理和計算機視覺領域的基本挑戰之一是圖像去噪，其基本目標是通過抑制噪聲污染版本圖像中的噪聲來估計原始圖像。圖像噪聲可能由傳感器和環境條件引起，這在實際情況中通常是無法避免的。因此，圖像去噪在圖像恢復、視覺跟踪、圖像配準、圖像分割和圖像分類等廣泛應用中發揮著重要作用，其中獲取原始圖像內容對於實現穩健性能至關重要。

# 1.3 Main idea

> The information in a mesh can be separated into two orthogonal components: a tangential and a normal component

> 網格中的信息可以分為兩個正交分量：切向分量和法向分量。

- 法線分量編碼形狀的幾何信息
- 切線分量保存參數信息

在此公式中，沿其法線方向移動頂點僅修改網格的幾何形狀。與這個概念相關的是演化曲線 [Osher 和 Sethian 1988]，其中點在法線方向上移動的距離與其曲率成正比，以便隨著時間的推移獲得更平滑的曲線

> 去噪方法就是基於這個想法，沿著它們的法線方向移動網格頂點。圖像去噪的廣泛研究奠定了基礎

# 1.4 what method can use?

有很多不同的去噪算法:
1. bilateral filtering (論文所使用的算法)
2. anisotropic diffusion [Barash 2002] 
3. robust statistics [Durand and Dorsey 2002]
4. Bayesian approaches [Elad 2001]

將這些算法從二維平面調整到三維表面並不簡單，主要有三個原因：
1. 不規則性；與圖像不同，網格在連通性和採樣方面都是不規則的
2. 收縮；圖像去噪算法通常不是能量保存算法。雖然這在圖像中不太明顯，但在網格中，這表現為網格的收縮
3. 漂移；圖像去噪技術的幼稚適應可能會導致稱為頂點漂移的偽影，其中網格的規則性會降低。

# 1.5 bilateral filtering 和 anisotropic diffusion 有甚麼差別?

## 有什麼相同的？

雙邊濾波和各向異性擴散背後的直覺是相同的：

- 平均可以很好地消除隨機噪聲；
- 平均應該只關注屬於同一區域的像素（從某種意義上說，它們是給定對象的給定顏色的像素）：
  1. 避免區域之間邊界處的偽影（最明顯的是模糊）
  2. 提高去噪效率（內部沒有異常值，平均效率更高）。

## 有什麼不同？

雙邊濾波和各向異性擴散將因它們如何實現這兩個目標而有所不同（在圖像分割不可用的約束下）。

通常，**各向異性擴散**在變分框架中表示，其中一些圖像泛函被最小化。這些泛函通常包含一個取決於要降噪圖像的梯度的項，因為該項允許觸發各向異性屬性。這些問題的解決方案通常通過一些梯度下降迭代獲得，但並非總是如此（在圖像形態學啟發的框架中，例如平均曲率運動，圖像水平線根據它們的曲率移動）。

基本上，這些泛函的解對應於均勻區域內的各向同性擴散，並且跨圖像邊緣的擴散由取決於圖像梯度的權重停止。

**雙邊濾波**是一種基於像素的方法。對於給定的像素，其去噪對應物是通過其鄰居的加權平均值獲得的，其中權重由取決於它們的顏色相似性和圖像距離的某個函數給出。與那時的各向異性擴散不同，該問題不是在圖像上全局解決，而是在每個像素周圍的每個鄰域上解決。此外，在給定像素上沒有明確的基於梯度的障礙：這種效果或多或少會因視覺距離函數中的衰減值而顯著。

請注意，當像素的雙邊鄰域變為無限時，您有一個稱為nonlocal mean的新算法。

# 1.6 usage code
The usage code from [github.com/bldeng/GuidedDenoising](https://github.com/bldeng/GuidedDenoising/blob/master/src/Denoising/Algorithms/BilateralMeshDenoising.cpp)

# 2.1 Mesh Saliency
> 我們的顯著性概念受到低級人類視覺系統線索的啟發。我們使用高斯加權平均曲率上的中心環繞算子以依賴於尺度的方式定義網格顯著性。我們觀察到，這樣的網格顯著性定義能夠捕獲大多數人認為網格上視覺上有趣的區域。與使用純幾何形狀度量（例如曲率）相比，由我們的網格顯著性運算符計算的受人類感知啟發的重要性度量在 3D 網格的處理和查看中產生了更令人愉悅的視覺結果。我們討論瞭如何將網格顯著性結合到圖形應用程序中，例如網格簡化和視點選擇，並提供了一些示例來展示使用網格顯著性產生的具有視覺吸引力的結果。

# 2.2 Why we need Mesh Saliency?
> 過去十年的研究為圖形和幾何建模中 3D 網格的表示和分析奠定了堅實的數學基礎。然而，這項工作的大部分內容並未明確納入低級人類視覺注意力模型。在本文中，我們介紹了網格顯著性的概念，作為圖形網格區域重要性的度量。

问题: 
判定mesh上各点的“重要程度”，这里的重要程度，基本上是指在不同尺度（分辨率）下，几何特征的重要程度。

> 圖 1：網格顯著性：圖像 (a) 顯示斯坦福犰狳模型，圖像 (b) 顯示其網格顯著性。
我們在本文中的目標是將基於感知的指標用於處理和查看 3D 網格的問題。諸如曲率之類的純幾何形狀度量在網格處理文獻中有著豐富的使用歷史

> 然而，純粹基於曲率的度量不一定是感知重要性的良好度量。例如，大體平坦區域中間的高曲率尖峰可能會被認為很重要。然而，密集重複的高曲率凸起中間的平坦區域也可能被認為也很重要。重複的圖案，即使曲率很高，在視覺上也是單調的。令人愉悅和感興趣的是不尋常或意想不到的事情。

> 例如，圖 2(a) 所示的犰狳腿部具有重複凸起的紋理區域可以說在視覺上沒有孤立但光滑的特徵（例如膝蓋）有趣（圖 2(c)）。
在本文中，我們介紹了網格顯著性的概念，即 3D 網格的區域重要性度量，並提出了一種計算方法。我們計算網格顯著性的方法使用中心環繞機制。


# 2.3 Main idea
基本思想: 
在求解各点的平均曲率基础上，计算该点平均曲率在邻域内的显著性。类似于二维图像中金字塔的方法，建立三维模型的金字塔。

算法: 
假设我们已经计算得到了三维模型每个点上的平均曲率 $\mathscr{C}$ ，以高斯函数为权重（实际上就是一个带权的邻域，但通过全局计算，避免了对邻域直接求解），取 $\sigma$ 为高斯函数方差（或半径），按照下式计算其高斯滤波后的平均曲率 $G (\mathscr{C}(v), \sigma)$ ：

G(C(v),σ)= 
∑ 
x∈N(v,2σ)
​
 e 
−∥x−v∥ 
2
 /(2σ 
2
 )
 
∑ 
x∈N(v,2σ)
​
 C(x)e 
−∥x−v∥ 
2
 /(2σ 
2
 )
 
​


$$
G (\mathscr{C}(v),σ)= 
\frac{∑ 
x∈N(v,2σ)
​
 e 
−∥x−v∥ 
2
 /(2σ 
2
 )
 }{∑ 
x∈N(v,2σ)
​
 C(x)e 
−∥x−v∥ 
2
 /(2σ 
2
 )}
​
$$

通过对不同 $\sigma$ 的选取，事实上我们建立了三维模型的高斯金字塔。对于一个给定的$\sigma$ ，重要程度 $\mathscr{S}(v)$ 计算方式如下：

$$
\mathscr{S}(v)=|G(\mathscr{C}(v), \sigma)-G(\mathscr{C}(v), 2 \sigma)|
$$

显然，这和二维图像中计算特征点的方式也非常类似。

如果我们选择了多个不同的 $\sigma_i$ ，那么我们也可以得到不同的  $\mathscr{S}_i$ 。对于不同分辨率下的Saliency，我们通过加权求和得到最终的Saliency。加权的原则是，如果Saliency方差越大，权重越大，方差越小，权重越小。因此我们首先对 $\mathscr{S}_i$ 归一化，然后选出其中最大值 $M_i$ 和平均值 $\bar{m}_i$ ，权重就是 $\left(M_{i}-\bar{m}_{i}\right)^{2}$ 。因此，最终的Saliency为 

$$
S=  \sum_{i}\left(M_{i}-\bar{m}_{i}\right)^{2}\mathscr{S}_i
$$
​
> where, σi is the standard deviation of the Gaussian filter at scale i. For all the results in this paper we have used five scales σi ∈ {2ε,3ε,4ε,5ε,6ε}, where ε is 0.3% of the length of the diagonal of the bounding box of the model.

# 2.4.1 Garland and Heckbert Method: QSlim
首先介绍QSlim算法，然后讲Saliency如何改进QSlim算法。QSlim算法基本思想，是每次合并一组相邻的顶点，使得顶点数量越来越少。对于每一个顶点 $v$ ，相邻平面组成的几何为 $P$ 。遍历每一个 $p ∈ P p \in P$ ，计算平面方程 $ax+by+cz+d=0,a^2+b^2+c^2=1$ ，将四个系数表示成 $p=(a~b~c~d)^T$ 。对于任何一点 $x$ ， $计算它到平面的距离为$ x x^Tpp^Txx$ 。计算它到顶点v vv邻近所有平面的距离之和，如果将 $pp^T$ 写成 $pQ_p$ ，则距离和为 $\sum_p x^TQ_px = x^T (\sum_p Q_p) x$ 。将 $\sum_p Q_p$ 记做 $Q_v$

对于一对相邻的点 $(v_i,v_j)$ ，分别计算 $v_i$ 到以 $v_j$ 为中心的所有面的距离，和 $v_j$ 到以 $v_i$ 为中心的所有面的距离，并求和，得到  $v_i^T Q_{v_j} v_i + v_j^T Q_{v_i} v_j$ 。如果我们要合并 $v_i$ 和 $v_j$ 到中间的一点 $\bar{v}$ ，则 $\bar{v}$ 对应的距离为 $\bar{v}^T (Q_{v_j} + Q_{v_i}) \bar{v}$（称之为Quadric）。对于每一条边，我们计算这 $\bar{v}$ 和对应的距离和，将最小距离和的那一对边进行合并。合并后，新的 $Q_{\bar{v}} = Q_{v_i} + Q_{v_j}$ ，并更新所有会影响到的邻近的边的 $\bar{v}$ 和Quadric值。

# 2.4.2 Salient Simplification
Saliency的改进是，包含模型特征的点不应该过早地被合并。因此，它给Quadric值之上，额外增加了一个权重项，这个权重项附带在每个顶点上，为

$$
W(v)=A(\mathscr{S}(v),α,λ)=
\begin{aligned}
  λ\mathscr{S}(v), && if \mathscr{S}(v)>=α\\ 
  \mathscr{S}(v), && if \mathscr{S}(v)<α
\end{aligned} 
$$

What is that means? 即如果Saliency小于某一阈值 $\alpha$，则权重就是Saliency值；如果大于阈值，则表示极其关键的特征，因此需尽量不被合并，因此再额外增加一个比例系数 $\lambda>1$ 。在原文中，作者取 $\lambda=100$ ， $\alpha$ 为第30大的saliency值。

注意到这个权重是加在顶点上的，对于边 $e(v_i,v_j)$ ，则权重为 $\mathscr{W}\left(v_{i}\right)+\mathscr{W}\left(v_{j}\right)$
原文给了一个例子，见Figure 9，可以看到，在Saliency权重下，特征得到了更好地保持

# 2.5 Salient Viewpoint Selection
假设在视角v下，能看到的部分模型表面顶点集合为 $F(v)$ 。则对于视角下的Saliency总和 $U(v)$，为 $U(v)=\Sigma_{x \in F(v)} \mathscr{S}(x)$ 显然，最佳视角应该是 $v_{m}=\operatorname{argmax}_v U(v)$ 。在Saliency算法之前，U(v)通常是所有可见顶点的平均曲率之和。

直接计算 $v_m$ 会非常耗时，作者使用了梯度下降的方法，先随机选择一个视角 $v(\theta,\phi)$ ，其中 $\theta$ 和 $\phi$ 分别表示经度和纬度。然后搜索附近的视角，选择使Saliency和最大的一个，重复上述过程。多选几个随机初始点，重复过程。

# 3.1 Fast and Effective Feature-Preserving Mesh Denoising
> 我們提出了一種簡單快速的網格去噪方法，可以在有效去除噪聲的同時保留銳邊和尖角等網格特徵。該方法包括兩個階段。
> 
> 首先，通過對相鄰人臉法線進行加權平均來迭代過濾噪聲人臉法線。
> 
> 其次，迭代更新頂點位置以與去噪後的面部法線一致。
> 
> 正常過濾期間使用的權重函數比以前類似方法中使用的權重函數簡單得多，只是一個修剪二次方。這使得該算法既快速又易於實現。頂點位置更新基於使用最小二乘誤差準則的表面法線積分。


# 3.2 Main idea

# 3.2.1 Normal Filtering
In the pervios paper of chapter 4.1 introduce different approachs of Normal Filtering, here the approach of they use is that formula below:

$$

n'_i = normalize(sum_{i \in N*_F(i)} h_j n_j) 

$$

where h_j is a weight function defined as

$$
h_j = \begin{aligned}
  f(n_i * n_j - T) && if n_i * n_j > T \\
  0 && if n_i * n_j <= T \\
\end{aligned}
$$

Here, $0 <= T <= 1$ is a threshold determined by the user, used to control averaging, and f(x) can be any suitably chosen monotonically increasing function for $x$ , in their experiments showed that $f(x) = x^2$ is a good choice.

# 3.2.2 Vertex Position Updating

$$

x'_i = x_i + \frac{1}{|F_v(i)|}\sum_{k \in F_v(i)} n'_k(n'_k * (c_k - x_i))

$$

or, equivalently,

$$

x'_i = \frac{1}{|F_v(i)|}\sum_{k \in F_v(i)} p_k(i)

$$

# 3.3 The result
# 3.3.1 Advantage
- In their experiments show that their approach is as fast as the bilateral filtering approach : like it can denoise the Buddha model of 1.5 million triangles within 7 seconds.
- this approach can preserve sharp edges better than the bilateral filtering approach
- Algorithm is also suitable for models with nonuniform triangles, even though they do not take the triangle area into account
# 3.3.2 Disadvantage
- it cannot effectively deal with meshes with lots of holes. If the normal denoising results are not very good due to undersmoothing or oversmoothing, the vertex updating step may result in nonoptimal positions, causing some geometric inconsistencies such as mesh folding, self-intersections, and poorly shaped triangles.

# 3.4 Usage code 
The usage code from [github.com/bldeng/GuidedDenoising](https://github.com/bldeng/GuidedDenoising)

updateFilteredNormals
```c++
void FastAndEffectiveFeaturePreservingMeshDenoising::updateFilteredNormals(TriMesh &mesh, std::vector<TriMesh::Normal> &filtered_normals)
{
// get parameter for normal update
    int face_neighbor_index;
    double threshold_T;
    int normal_iteration_number;

    std::vector< std::vector<TriMesh::FaceHandle> > all_face_neighbor;
    getAllFaceNeighbor(mesh, all_face_neighbor, face_neighbor_type, true);

    filtered_normals.resize(mesh.n_faces());

    std::vector<TriMesh::Normal> previous_normals;
    getFaceNormal(mesh, previous_normals);

    for(int iter = 0; iter < normal_iteration_number; iter++)
    {
        for(TriMesh::FaceIter f_it = mesh.faces_begin(); f_it != mesh.faces_end(); f_it++)
        {
            TriMesh::Normal ni = previous_normals[f_it->idx()];
            std::vector<TriMesh::FaceHandle> face_neighbor = all_face_neighbor[f_it->idx()];
            TriMesh::Normal temp_normal(0.0, 0.0, 0.0);
            for(int i = 0; i <(int)face_neighbor.size(); i++)
            {
                TriMesh::Normal nj = previous_normals[face_neighbor[i].idx()];
                double value = (ni | nj) - threshold_T;
                double weight = (value > 0) ? value * value : 0;
                temp_normal += nj * weight;
            }
            temp_normal.normalize();
            filtered_normals[f_it->idx()] = temp_normal;
        }
        previous_normals = filtered_normals;
    }
}
```